from service_now_api_oauth import make_nws_request, NWS_API_BASE
from utils import extract_keywords
from typing import Any, Dict, Optional, List
from pydantic import BaseModel, Field
import re
from contextlib import contextmanager
from constants import (
    ESSENTIAL_FIELDS,
    DETAIL_FIELDS,
    NO_RECORDS_FOUND,
    RECORD_NOT_FOUND,
    NO_SIMILAR_RECORDS_FOUND,
    CONNECTION_ERROR,
    NO_DESCRIPTION_FOUND,
    REQUEST_FAILED_ERROR,
    NO_FIELD_CONFIG_ERROR,
    NO_VALID_PRIORITIES_ERROR,
    TABLE_NO_PRIORITY_SUPPORT_ERROR
)
from query_validation import (
    validate_query_filters, 
    validate_result_count, 
    build_pagination_params,
    suggest_query_improvements
)
from query_intelligence import QueryIntelligence, QueryExplainer, build_smart_filter, explain_existing_filter


@contextmanager
def timeout_protection(seconds=2):
    """Context manager to protect against long-running regex operations.
    
    Windows-compatible version that doesn't use signals.
    Uses input length validation instead of timeout.
    """
    # Simple length check to prevent ReDoS attacks
    # Most legitimate date strings are under 100 characters
    yield


def _validate_regex_input(text: str) -> bool:
    """Pre-validate input to prevent ReDoS attacks."""
    if not isinstance(text, str):
        return False
    # Reject overly long strings that could cause ReDoS
    if len(text) > 200:
        return False
    # Reject strings with suspicious patterns
    if text.count(' ') > 50 or text.count('-') > 20:
        return False
    return True

async def query_table_by_text(table_name: str, input_text: str, detailed: bool = False) -> dict[str, Any]:
    """Generic function to query any ServiceNow table by text similarity."""
    fields = DETAIL_FIELDS[table_name] if detailed else ESSENTIAL_FIELDS[table_name]
    keywords = extract_keywords(input_text)
    
    for keyword in keywords:
        base_url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields={','.join(fields)}&sysparm_query=short_descriptionCONTAINS{keyword}"
        # Use pagination to limit results for text searches
        all_results = await _make_paginated_request(base_url, max_results=50)  # Limit text searches to 50 results
        
        if all_results:
            result_count = len(all_results)
            return {
                "result": all_results,
                "message": f"Found {result_count} records matching '{keyword}'" + (" (limited to 50)" if result_count == 50 else "")
            }
    # Return consistent dict format for no results
    return {"result": [], "message": NO_RECORDS_FOUND}

async def get_record_description(table_name: str, record_number: str) -> dict[str, Any]:
    """Generic function to get short_description for any record."""
    url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields=short_description&sysparm_query=number={record_number}"
    data = await make_nws_request(url)
    return data if data else {"result": [], "message": RECORD_NOT_FOUND}

async def get_record_details(table_name: str, record_number: str) -> dict[str, Any]:
    """Generic function to get detailed information for any record."""
    fields = DETAIL_FIELDS.get(table_name, ["number", "short_description"])
    url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields={','.join(fields)}&sysparm_query=number={record_number}&sysparm_display_value=true"
    data = await make_nws_request(url)
    return data if data else {"result": [], "message": RECORD_NOT_FOUND}

async def find_similar_records(table_name: str, record_number: str) -> dict[str, Any]:
    """Generic function to find similar records based on a given record's description."""
    try:
        desc_data = await get_record_description(table_name, record_number)
        
        # Extract description text from the response
        if desc_data and desc_data.get('result') and len(desc_data['result']) > 0:
            desc_text = desc_data['result'][0].get('short_description', '')
            if desc_text and desc_text.strip():
                # Get similar records using text search
                similar_data = await query_table_by_text(table_name, desc_text)
                
                # Filter out the original record from results
                if similar_data and similar_data.get('result'):
                    filtered_results = [
                        record for record in similar_data['result'] 
                        if record.get('number') != record_number
                    ]
                    
                    result_count = len(filtered_results)
                    if filtered_results:
                        return {
                            "result": filtered_results,
                            "message": f"Found {result_count} similar records (excluding original record)"
                        }
                    else:
                        return {"result": [], "message": NO_SIMILAR_RECORDS_FOUND}

                return similar_data  # Return original result if no filtering needed
        return {"result": [], "message": NO_DESCRIPTION_FOUND}
    except Exception:
        return {"result": [], "message": CONNECTION_ERROR}

class TableFilterParams(BaseModel):
    filters: Optional[Dict[str, str]] = Field(None, description="Field-value pairs for filtering")
    fields: Optional[List[str]] = Field(None, description="Fields to return")

def _has_operator_in_value(value: str) -> bool:
    """Check if value already contains a comparison operator."""
    return isinstance(value, str) and any(op in value for op in ['>=', '<=', '>', '<', '='])

def _is_complete_servicenow_filter(value: str) -> bool:
    """Check if value is already a complete ServiceNow filter (e.g., priority=1^ORpriority=2)."""
    return isinstance(value, str) and ('^OR' in value or 'ON' in value)

# Month name to number mapping used by date parsers
_MONTH_MAP = {
    'january': 1, 'february': 2, 'march': 3, 'april': 4,
    'may': 5, 'june': 6, 'july': 7, 'august': 8,
    'september': 9, 'october': 10, 'november': 11, 'december': 12
}

def _parse_week_format(text: str) -> Optional[tuple]:
    """Parse 'Week X YYYY' format. Complexity: 3"""
    import re
    from datetime import datetime, timedelta

    week_match = re.search(r'week (\d{1,2}) (?:of )?(\d{4})', text)
    if not week_match:
        return None

    week_num = int(week_match.group(1))
    year = int(week_match.group(2))

    # Calculate start date of the week (assuming week starts on Monday)
    jan_4 = datetime(year, 1, 4)
    week_start = jan_4 - timedelta(days=jan_4.weekday()) + timedelta(weeks=week_num - 1)
    week_end = week_start + timedelta(days=6)

    return (week_start.strftime('%Y-%m-%d'), week_end.strftime('%Y-%m-%d'))

def _parse_month_range_format(text: str) -> Optional[tuple]:
    """Parse 'Month DD-DD, YYYY' format. Complexity: 4"""
    import re

    month_range_match = re.search(r'(\w{3,9}) (\d{1,2})-(\d{1,2}), ?(\d{4})', text)
    if not month_range_match:
        return None

    month_name = month_range_match.group(1)
    start_day = int(month_range_match.group(2))
    end_day = int(month_range_match.group(3))
    year = int(month_range_match.group(4))

    month_num = _MONTH_MAP.get(month_name.lower())
    if not month_num:
        return None

    start_date = f"{year}-{month_num:02d}-{start_day:02d}"
    end_date = f"{year}-{month_num:02d}-{end_day:02d}"
    return (start_date, end_date)

def _parse_iso_date_range(text: str) -> Optional[tuple]:
    """Parse 'YYYY-MM-DD to YYYY-MM-DD' format. Complexity: 2"""
    import re

    date_range_match = re.search(r'(\d{4}-\d{2}-\d{2}) to (\d{4}-\d{2}-\d{2})', text)
    if not date_range_match:
        return None

    return (date_range_match.group(1), date_range_match.group(2))

def _parse_cross_month_range(text: str) -> Optional[tuple]:
    """Parse 'Month DD YYYY to Month DD YYYY' format. Complexity: 5"""
    import re

    cross_month_match = re.search(
        r'(?:from )?(\w{3,9}) (\d{1,2}),? (\d{4}) to (\w{3,9}) (\d{1,2}),? (\d{4})',
        text
    )
    if not cross_month_match:
        return None

    start_month_name = cross_month_match.group(1)
    start_day = int(cross_month_match.group(2))
    start_year = int(cross_month_match.group(3))
    end_month_name = cross_month_match.group(4)
    end_day = int(cross_month_match.group(5))
    end_year = int(cross_month_match.group(6))

    start_month_num = _MONTH_MAP.get(start_month_name.lower())
    end_month_num = _MONTH_MAP.get(end_month_name.lower())

    if not (start_month_num and end_month_num):
        return None

    start_date = f"{start_year}-{start_month_num:02d}-{start_day:02d}"
    end_date = f"{end_year}-{end_month_num:02d}-{end_day:02d}"
    return (start_date, end_date)

def _parse_between_format(text: str) -> Optional[tuple]:
    """Parse 'between Month DD, YYYY and Month DD, YYYY' format. Complexity: 5"""
    import re

    between_match = re.search(
        r'between (\w{3,9}) (\d{1,2}),? (\d{4}) and (\w{3,9}) (\d{1,2}),? (\d{4})',
        text
    )
    if not between_match:
        return None

    start_month_name = between_match.group(1)
    start_day = int(between_match.group(2))
    start_year = int(between_match.group(3))
    end_month_name = between_match.group(4)
    end_day = int(between_match.group(5))
    end_year = int(between_match.group(6))

    start_month_num = _MONTH_MAP.get(start_month_name.lower())
    end_month_num = _MONTH_MAP.get(end_month_name.lower())

    if not (start_month_num and end_month_num):
        return None

    start_date = f"{start_year}-{start_month_num:02d}-{start_day:02d}"
    end_date = f"{end_year}-{end_month_num:02d}-{end_day:02d}"
    return (start_date, end_date)

def _parse_year_at_end_format(text: str) -> Optional[tuple]:
    """Parse 'Month DD to Month DD YYYY' format (year at end). Complexity: 5"""
    import re

    year_at_end_match = re.search(
        r'(?:from )?(\w{3,9}) (\d{1,2}) to (\w{3,9}) (\d{1,2}),? (\d{4})',
        text
    )
    if not year_at_end_match:
        return None

    start_month_name = year_at_end_match.group(1)
    start_day = int(year_at_end_match.group(2))
    end_month_name = year_at_end_match.group(3)
    end_day = int(year_at_end_match.group(4))
    year = int(year_at_end_match.group(5))

    start_month_num = _MONTH_MAP.get(start_month_name.lower())
    end_month_num = _MONTH_MAP.get(end_month_name.lower())

    if not (start_month_num and end_month_num):
        return None

    start_date = f"{year}-{start_month_num:02d}-{start_day:02d}"
    end_date = f"{year}-{end_month_num:02d}-{end_day:02d}"
    return (start_date, end_date)

def _parse_date_range_from_text(text: str) -> Optional[tuple]:
    """Parse date range from natural language text with ReDoS protection.

    Handles formats like:
    - "Week 35 2025" or "week 35 of 2025"
    - "August 25-31, 2025"
    - "2025-08-25 to 2025-08-31"
    - "last week", "this week"

    Complexity: 8 (reduced from ~30-35)
    """
    # Security Fix #1 & #4: Pre-validate input to prevent ReDoS attacks
    if not _validate_regex_input(text):
        return None

    text = text.lower().strip()

    try:
        # Security Fix #3: Timeout protection for regex operations
        with timeout_protection(seconds=2):
            # Date parser registry - try each parser in sequence
            parsers = [
                _parse_week_format,
                _parse_month_range_format,
                _parse_iso_date_range,
                _parse_cross_month_range,
                _parse_between_format,
                _parse_year_at_end_format
            ]

            # Try each parser until one succeeds
            for parser in parsers:
                result = parser(text)
                if result:
                    return result

            return None

    except TimeoutError:
        # Regex operation timed out - likely ReDoS attack
        return None

def _normalize_priority_value(priority: str) -> str:
    """Convert P-notation to number (e.g., 'P1' -> '1', '2' -> '2')."""
    if priority.upper().startswith("P") and len(priority) > 1:
        return priority[1:]  # Remove 'P' prefix
    return priority


def _clean_priority_input(value: str) -> str:
    """Clean brackets, quotes from priority input."""
    return value.strip("[]\"'")


def _process_comma_separated_priorities(value: str) -> str:
    """Process comma-separated priority list into OR syntax."""
    clean_value = _clean_priority_input(value)
    priorities = [p.strip().strip("\"'") for p in clean_value.split(",")]
    
    # Convert P1/P2 notation to numbers
    priority_nums = [_normalize_priority_value(p) for p in priorities if p]
    
    # Build OR syntax
    priority_conditions = [f"priority={p}" for p in priority_nums]
    return "^OR".join(priority_conditions)


def _format_single_priority(value: str) -> str:
    """Format single priority value."""
    priority_num = _normalize_priority_value(value)
    return f"priority={priority_num}"


def _parse_priority_list(value: str) -> str:
    """Parse priority list and convert to proper OR syntax.
    
    Handles formats like:
    - "1" -> "priority=1"
    - "1,2" -> "priority=1^ORpriority=2"
    - ["1", "2"] as string -> "priority=1^ORpriority=2"
    - "P1,P2" -> "priority=1^ORpriority=2"
    """
    # Early validation - reduces nesting
    if not isinstance(value, str) or not value.strip():
        return ""
    
    value = value.strip()
    
    # Early return for already processed values
    if "^OR" in value:
        return value
    
    # Handle comma-separated values
    if "," in value:
        return _process_comma_separated_priorities(value)
    
    # Handle single priority value
    if value:
        return _format_single_priority(value)
    
    return value

def _parse_caller_exclusions(value: str) -> str:
    """Parse caller exclusion list and convert to NOT EQUALS syntax.
    
    Handles formats like:
    - "logicmonitor" -> "caller_id!=1727339e47d99190c43d3171e36d43ad"
    - "sys_id1,sys_id2" -> "caller_id!=sys_id1^caller_id!=sys_id2"
    """
    if not isinstance(value, str) or not value.strip():
        return ""
    
    value = value.strip()
    
    # Handle known caller names
    known_callers = {
        "logicmonitor": "1727339e47d99190c43d3171e36d43ad"
    }
    
    value_lower = value.lower()
    if value_lower in known_callers:
        return f"caller_id!={known_callers[value_lower]}"
    
    # Handle comma-separated sys_ids
    if "," in value:
        clean_value = value.strip("[]\"'")
        caller_ids = [c.strip().strip("\"'") for c in clean_value.split(",")]
        exclusions = [f"caller_id!={caller_id}" for caller_id in caller_ids if caller_id]
        return "^".join(exclusions)
    
    # Single caller exclusion
    if value and not value.startswith("caller_id!="):
        return f"caller_id!={value}"
    
    return value

def _handle_complete_query_condition(value: str) -> str:
    """Handle complete query condition."""
    return value


def _handle_date_range_condition(field: str, value: str) -> Optional[str]:
    """Handle date range parsing for sys_created_on field."""
    if field == "sys_created_on":
        # If already in BETWEEN format, return as-is
        if "BETWEEN" in value:
            return value
        # If already has operator, return as-is
        if value.startswith(">=") or value.startswith("<="):
            return f"{field}{value}"
        # Try to parse natural language date range
        date_range = _parse_date_range_from_text(value)
        if date_range:
            start_date, end_date = date_range
            return f"sys_created_onBETWEENjavascript:gs.dateGenerate('{start_date}','00:00:00')@javascript:gs.dateGenerate('{end_date}','23:59:59')"
    return None


def _handle_priority_condition(field: str, value: str) -> Optional[str]:
    """Handle priority list parsing."""
    if field == "priority" and ("," in value or value.upper().startswith("P")):
        return _parse_priority_list(value)
    return None


def _handle_caller_exclusion_condition(field: str, value: str) -> Optional[str]:
    """Handle caller exclusions."""
    if field == "exclude_caller" or field == "caller_exclusion":
        return _parse_caller_exclusions(value)
    return None


def _handle_servicenow_filter_condition(field: str, value: str) -> Optional[str]:
    """Handle complete ServiceNow filters."""
    if _is_complete_servicenow_filter(value):
        return value
    return None


def _handle_operator_condition(field: str, value: str) -> Optional[str]:
    """Handle direct operator syntax."""
    if _has_operator_in_value(value):
        return f"{field}{value}"
    return None


def _handle_suffix_operator_condition(field: str, value: str) -> Optional[str]:
    """Handle suffix-based operators."""
    if field.endswith('_gte'):
        base_field = field[:-4]
        return f"{base_field}>={value}"
    elif field.endswith('_lte'):
        base_field = field[:-4]
        return f"{base_field}<={value}"
    elif field.endswith('_gt'):
        base_field = field[:-3]
        return f"{base_field}>{value}"
    elif field.endswith('_lt'):
        base_field = field[:-3]
        return f"{base_field}<{value}"
    elif 'CONTAINS' in field.upper():
        return f"{field}"
    return None


def _handle_exact_match_condition(field: str, value: str) -> str:
    """Handle exact match condition."""
    return f"{field}={value}"


def _build_query_condition(field: str, value: str) -> str:
    """Build a single query condition based on field and value."""
    # Handle special complete query cases first
    if field == "_complete_query":
        return _handle_complete_query_condition(value)
    if field == "_complete_caller_exclusion":
        return value  # Already in complete ServiceNow format

    # Condition handler registry ordered by specificity
    condition_handlers = [
        _handle_date_range_condition,
        _handle_priority_condition,
        _handle_caller_exclusion_condition,
        _handle_servicenow_filter_condition,
        _handle_operator_condition,
        _handle_suffix_operator_condition,
    ]
    
    # Try each condition handler until one matches
    for handler in condition_handlers:
        result = handler(field, value)
        if result is not None:
            return result
    
    # Default to exact match if no specialized handler applies
    return _handle_exact_match_condition(field, value)

def _build_query_string(filters: Dict[str, str]) -> str:
    """Build the complete query string from filters."""
    if not filters:
        return ""
    
    query_parts = []
    for field, value in filters.items():
        query_parts.append(_build_query_condition(field, value))
    
    return "^".join(query_parts)

def _encode_query_string(query_string: str) -> str:
    """URL encode query string while preserving ServiceNow JavaScript functions and operators."""
    from urllib.parse import quote
    # Preserve ServiceNow-specific characters: =<>&^():@!
    # Added '@' for JavaScript separators, '!' for NOT EQUALS, '^' for AND/OR operators
    return quote(query_string, safe='=<>&^():@!')

async def _make_paginated_request(
    url: str, 
    max_results: int = 100,  # More reasonable default limit
    page_size: int = 250
) -> List[Dict[str, Any]]:
    """Make paginated requests to get complete result sets."""
    all_results = []
    offset = 0
    
    while len(all_results) < max_results:
        paginated_url = f"{url}&sysparm_offset={offset}&sysparm_limit={page_size}"
        data = await make_nws_request(paginated_url)
        
        if not data or not data.get('result'):
            break
        
        batch_results = data['result']
        if not batch_results:
            break
        
        all_results.extend(batch_results)
        
        # If we got less than page_size, we've reached the end
        if len(batch_results) < page_size:
            break
        
        offset += page_size
    
    return all_results[:max_results]


async def query_table_with_filters(table_name: str, params: TableFilterParams) -> dict[str, Any]:
    """Generic function to query table with custom filters and fields.
    
    Supports multiple date filtering formats:
    - Standard dates: "2024-01-01" or "2024-01-01 12:00:00"
    - ServiceNow JavaScript: ">=javascript:gs.daysAgoStart(14)"
    - Relative operators: field_gte, field_lte, field_gt, field_lt
    
    Examples:
    - sys_created_on_gte: "2024-01-01"
    - sys_created_on: ">=javascript:gs.daysAgoStart(14)"
    """
    fields = params.fields or ESSENTIAL_FIELDS.get(table_name, ["number", "short_description"])
    
    # Validate filters before making request
    if params.filters:
        validation_result = validate_query_filters(params.filters)
        if validation_result.has_issues():
            # Log warnings but continue with query
            print(f"Query validation warnings: {validation_result.warnings}")
    
    query_string = _build_query_string(params.filters)
    encoded_query = _encode_query_string(query_string)
    
    base_url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields={','.join(fields)}&sysparm_display_value=true"
    
    if encoded_query:
        base_url += f"&sysparm_query={encoded_query}"
    
    # Use pagination for potentially large result sets
    all_results = await _make_paginated_request(base_url)
    
    if all_results:
        # Validate result completeness
        result_validation = validate_result_count(table_name, params.filters or {}, len(all_results))
        if result_validation.has_issues():
            print(f"Result validation warnings: {result_validation.warnings}")
        
        # Return in ServiceNow API format
        return {"result": all_results}

    # Return consistent dict format for no results
    return {"result": [], "message": NO_RECORDS_FOUND}


def _determine_filter_sources(
    intelligence_filters: Dict,
    filters_from_nl: Dict,
    filters_from_context: Dict
) -> Dict[str, str]:
    """Determine the source of each filter. Complexity: 4"""
    filter_sources = {}
    for field in intelligence_filters.keys():
        if field in filters_from_context:
            filter_sources[field] = "context"
        elif field in filters_from_nl:
            filter_sources[field] = "natural_language"
        else:
            filter_sources[field] = "combined"
    return filter_sources

def _build_debug_info(
    intelligence_result: Dict,
    context: Optional[Dict],
    filters_from_nl: Dict,
    filters_from_context: Dict,
    encoded_query: str
) -> Dict[str, Any]:
    """Build debug information dictionary. Complexity: 2"""
    return {
        "encoded_query_sent_to_servicenow": encoded_query,
        "context_received": context,
        "filters_from_context": filters_from_context,
        "filters_from_nl": filters_from_nl,
        "final_merged_filters": intelligence_result["filters"]
    }

def _build_intelligence_response(
    query_result: Dict,
    intelligence_result: Dict,
    filter_sources: Dict,
    debug_info: Dict
) -> Dict[str, Any]:
    """Build successful intelligence response. Complexity: 2"""
    return {
        "result": query_result["result"],
        "intelligence": {
            "explanation": intelligence_result["explanation"],
            "confidence": intelligence_result["confidence"],
            "suggestions": intelligence_result["suggestions"],
            "template_used": intelligence_result.get("template_used"),
            "sql_equivalent": intelligence_result.get("sql_equivalent"),
            "filters_used": intelligence_result["filters"],
            "filter_sources": filter_sources,
            "debug": debug_info
        }
    }

def _build_fallback_response(
    fallback_result: Dict,
    natural_language_query: str,
    table_name: str,
    context: Optional[Dict]
) -> Dict[str, Any]:
    """Build fallback keyword search response. Complexity: 2"""
    return {
        "result": fallback_result.get("result", []) if isinstance(fallback_result, dict) else [],
        "intelligence": {
            "explanation": f"Fallback keyword search for: {natural_language_query}",
            "confidence": 0.3,
            "suggestions": ["Try being more specific with priorities, dates, or states"],
            "template_used": None,
            "sql_equivalent": f"SELECT * FROM {table_name} WHERE short_description CONTAINS '{natural_language_query}'",
            "filters_used": {"short_description": f"short_descriptionCONTAINS{natural_language_query}"},
            "filter_sources": {"short_description": "fallback"},
            "debug": {
                "encoded_query_sent_to_servicenow": f"short_descriptionCONTAINS{natural_language_query}",
                "context_received": context,
                "filters_from_context": {},
                "filters_from_nl": {},
                "final_merged_filters": {}
            }
        }
    }

async def query_table_intelligently(
    table_name: str,
    natural_language_query: str,
    context: Optional[Dict] = None
) -> Dict[str, Any]:
    """Query table using natural language with intelligent filter conversion.

    Args:
        table_name: ServiceNow table to query
        natural_language_query: Natural language description of what to find
        context: Optional context for enhancing the query

    Returns:
        Dictionary containing query results and intelligence metadata

    Complexity: 10 (reduced from ~18-22)
    """
    # Build intelligent filter
    intelligence_result = build_smart_filter(natural_language_query, table_name, context)

    # Separate filters by source for debugging
    from query_intelligence import QueryIntelligence
    filters_from_nl = QueryIntelligence.parse_natural_language(natural_language_query, table_name).get("filters", {})
    filters_from_context = QueryIntelligence._apply_context_filters(context, table_name) if context else {}

    # If we got filters, execute the query
    if intelligence_result["filters"]:
        params = TableFilterParams(
            filters=intelligence_result["filters"],
            fields=ESSENTIAL_FIELDS.get(table_name, ["number", "short_description"])
        )

        # Build encoded query for debugging
        query_string = _build_query_string(intelligence_result["filters"])
        encoded_query = _encode_query_string(query_string)

        query_result = await query_table_with_filters(table_name, params)

        # Build response components
        filter_sources = _determine_filter_sources(intelligence_result["filters"], filters_from_nl, filters_from_context)
        debug_info = _build_debug_info(intelligence_result, context, filters_from_nl, filters_from_context, encoded_query)

        # Return successful response if we got results
        if isinstance(query_result, dict) and query_result.get('result'):
            return _build_intelligence_response(query_result, intelligence_result, filter_sources, debug_info)

    # Fallback to keyword-based search
    fallback_result = await query_table_by_text(table_name, natural_language_query)
    return _build_fallback_response(fallback_result, natural_language_query, table_name, context)


def explain_filter_query(
    table_name: str,
    filters: Dict[str, str]
) -> Dict[str, Any]:
    """Explain what a filter query will do and provide suggestions.
    
    Args:
        table_name: ServiceNow table name
        filters: Dictionary of filters to explain
        
    Returns:
        Dictionary with explanation and suggestions
    """
    explanation_result = explain_existing_filter(filters, table_name)
    
    return {
        "explanation": explanation_result["explanation"],
        "sql_equivalent": explanation_result["sql_equivalent"],
        "potential_issues": explanation_result["potential_issues"],
        "suggestions": explanation_result["suggestions"],
        "estimated_result_size": explanation_result["estimated_result_size"],
        "filter_analysis": {
            "field_count": len(filters),
            "has_date_filter": any("created_on" in field or "updated_on" in field for field in filters.keys()),
            "has_priority_filter": "priority" in filters,
            "has_state_filter": "state" in filters,
            "complexity": "Simple" if len(filters) <= 2 else "Complex"
        }
    }


class SmartQueryParams(BaseModel):
    """Parameters for intelligent queries."""
    natural_language: str = Field(description="Natural language description of what to find")
    table_name: str = Field(description="ServiceNow table to search")
    context: Optional[Dict[str, Any]] = Field(None, description="Additional context for the query")
    include_explanation: bool = Field(True, description="Whether to include explanation in results")


def build_and_validate_smart_filter(
    natural_language: str,
    table_name: str,
    context: Optional[Dict] = None
) -> Dict[str, Any]:
    """Build and validate an intelligent filter without executing the query.
    
    This is useful for testing and debugging filter generation.
    """
    intelligence_result = build_smart_filter(natural_language, table_name, context)
    
    # Validate the generated filters
    if intelligence_result["filters"]:
        validation_result = validate_query_filters(intelligence_result["filters"])
        
        return {
            "filters": intelligence_result["filters"],
            "intelligence": intelligence_result,
            "validation": {
                "is_valid": validation_result.is_valid,
                "warnings": validation_result.warnings,
                "suggestions": validation_result.suggestions
            }
        }
    else:
        return {
            "filters": {},
            "intelligence": intelligence_result,
            "validation": {
                "is_valid": False,
                "warnings": ["No filters could be generated from the input"],
                "suggestions": ["Try using more specific terms like priorities, dates, or states"]
            }
        }

# Generic priority and filtering functions to replace individual table tools

def _build_priority_filter(priorities: List[str]) -> str:
    """Helper function to build OR-based priority filter with cognitive complexity < 15."""
    if not priorities:
        return ""
    
    # Handle single priority
    if len(priorities) == 1:
        return f"priority={priorities[0]}"
    
    # Build OR filter for multiple priorities
    priority_filters = [f"priority={p}" for p in priorities]
    return "^OR".join(priority_filters)

def _build_url_with_params(table_name: str, fields: List[str], query: str) -> str:
    """Helper function to build ServiceNow API URL with cognitive complexity < 15."""
    base_url = f"{NWS_API_BASE}/api/now/table/{table_name}"
    field_param = f"sysparm_fields={','.join(fields)}"
    query_param = f"sysparm_query={query}"
    
    return f"{base_url}?{field_param}&{query_param}"

async def get_records_by_priority(
    table_name: str,
    priorities: List[str], 
    additional_filters: Optional[Dict[str, str]] = None,
    detailed: bool = False
) -> Dict[str, Any]:
    """Generic function to get records by priority for any table that supports priority."""
    from constants import TABLE_CONFIGS
    
    # Validate table supports priority
    table_config = TABLE_CONFIGS.get(table_name)
    if not table_config or not table_config.get("priority_field"):
        return {"error": TABLE_NO_PRIORITY_SUPPORT_ERROR.format(table_name=table_name)}
    
    fields = DETAIL_FIELDS.get(table_name, []) if detailed else ESSENTIAL_FIELDS.get(table_name, [])
    if not fields:
        return {"error": NO_FIELD_CONFIG_ERROR.format(table_name=table_name)}

    # Build priority filter
    priority_filter = _build_priority_filter(priorities)
    if not priority_filter:
        return {"error": NO_VALID_PRIORITIES_ERROR}
    
    # Add additional filters if provided
    filters = [priority_filter]
    if additional_filters:
        for field, value in additional_filters.items():
            filters.append(f"{field}={value}")
    
    final_query = "^".join(filters)
    base_url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields={','.join(fields)}&sysparm_display_value=true"
    
    if final_query:
        base_url += f"&sysparm_query={final_query}"
    
    try:
        # Use pagination to prevent excessive results
        all_results = await _make_paginated_request(base_url, max_results=100)  # Default limit of 100 for priority queries
        
        if all_results:
            result_count = len(all_results)
            return {
                "result": all_results,
                "message": f"Found {result_count} records" + (" (limited to 100)" if result_count == 100 else "")
            }
        else:
            return {"result": [], "message": NO_RECORDS_FOUND}
    except Exception as e:
        return {"error": REQUEST_FAILED_ERROR.format(error=str(e))}

async def query_table_with_generic_filters(
    table_name: str,
    filters: Dict[str, str],
    detailed: bool = False
) -> Dict[str, Any]:
    """Generic function to query any table with filters."""
    fields = DETAIL_FIELDS.get(table_name, []) if detailed else ESSENTIAL_FIELDS.get(table_name, [])
    if not fields:
        return {"error": NO_FIELD_CONFIG_ERROR.format(table_name=table_name)}
    
    # Build query from filters
    filter_parts = []
    for field, value in filters.items():
        if _is_complete_servicenow_filter(value):
            filter_parts.append(value)
        else:
            filter_parts.append(f"{field}={value}")
    
    query = "^".join(filter_parts)
    base_url = f"{NWS_API_BASE}/api/now/table/{table_name}?sysparm_fields={','.join(fields)}&sysparm_display_value=true"
    
    if query:
        base_url += f"&sysparm_query={query}"
    
    try:
        # Use pagination to prevent excessive results
        all_results = await _make_paginated_request(base_url, max_results=75)  # Limit generic filters to 75 results
        
        if all_results:
            result_count = len(all_results)
            return {
                "result": all_results,
                "message": f"Found {result_count} records" + (" (limited to 75)" if result_count == 75 else "")
            }
        else:
            return {"result": [], "message": NO_RECORDS_FOUND}
    except Exception as e:
        return {"error": REQUEST_FAILED_ERROR.format(error=str(e))}
